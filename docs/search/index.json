[{"content":"問題 brewで asdf のバージョンを 0.11.1 から 0.13.1 に上げたときに asdf コマンドが効かなくなりました。\n1 2 3 ❯ asdf Unknown command: `asdf ` /opt/homebrew/opt/asdf/libexec/bin/asdf: line 117: /opt/homebrew/Cellar/asdf/0.11.1/libexec/lib/commands/command-help.bash: No such file or directory 原因 環境変数 $ASDF_DIR で古いバージョンを指定していた。\n1 2 3 4 vi ~/.zshrc # 以下の記述が... export ASDF_DIR=/opt/homebrew/Cellar/asdf/0.11.1/libexec /opt/homebrew/Cellar/asdf/0.13.1/libexecに書き換えようと思ったけどそもそもこれ指定しなくてよいのでは？と思いコメントアウトして再読み込みすると、、、\n1 2 3 4 ❯ asdf version: v0.13.1 MANAGE PLUGINS 普通に使えました。\n過去の自分はなぜこの環境変数を使ったのか謎。\n","date":"2023-10-25T00:30:26+09:00","permalink":"https://blaaackard.com/p/asdf_dir/","title":"brew で asdf のバージョン上げたら使えなくなった"},{"content":"最初に Kubernetes初心者の私は特にNamespace「kube-system」にあるリソースについて意識せずに業務を進めていました。\nそこで今回はGKE(Google Cloud Kubernetes Engine)でクラスタ構築時に勝手に作成されるリソースがどのような働きをしているのか雑にまとめてみることにしました。\nまずはクラスタを構築して、、、 特に何もデプロイせずにk get allをします。\n実行結果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 ❯ k get all -n kube-system NAME READY STATUS RESTARTS AGE pod/event-exporter-gke-7bf6c99dcb-ddh8w 2/2 Running 0 3m14s pod/fluentbit-gke-sdpcc 2/2 Running 0 2m14s pod/gke-metrics-agent-mztgr 2/2 Running 0 2m14s pod/konnectivity-agent-69fc69d588-t67rj 1/1 Running 0 3m3s pod/konnectivity-agent-autoscaler-5d9dbcc6d8-2qlgw 1/1 Running 0 3m2s pod/kube-dns-5bfd847c64-p6tgx 4/4 Running 0 3m22s pod/kube-dns-autoscaler-84b8db4dc7-2sjtc 1/1 Running 0 3m21s pod/kube-proxy-gke-cn-matsuirut-temp-default-pool-14ae721e-qj9s 1/1 Running 0 72s pod/l7-default-backend-d86c96845-nj87m 1/1 Running 0 3m pod/metrics-server-v0.5.2-6bf74b5d5f-wvrqq 2/2 Running 0 91s pod/pdcsi-node-pvztw 2/2 Running 0 2m14s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/default-http-backend NodePort 10.248.14.194 \u0026lt;none\u0026gt; 80:30274/TCP 2m59s service/kube-dns ClusterIP 10.248.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 3m23s service/metrics-server ClusterIP 10.248.8.65 \u0026lt;none\u0026gt; 443/TCP 2m50s NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE daemonset.apps/fluentbit-gke 1 1 1 1 1 kubernetes.io/os=linux 3m12s daemonset.apps/fluentbit-gke-256pd 0 0 0 0 0 kubernetes.io/os=linux 3m12s daemonset.apps/fluentbit-gke-max 0 0 0 0 0 kubernetes.io/os=linux 3m12s daemonset.apps/gke-metrics-agent 1 1 1 1 1 \u0026lt;none\u0026gt; 3m8s daemonset.apps/gke-metrics-agent-scaling-10 0 0 0 0 0 \u0026lt;none\u0026gt; 3m8s daemonset.apps/gke-metrics-agent-scaling-100 0 0 0 0 0 \u0026lt;none\u0026gt; 3m7s daemonset.apps/gke-metrics-agent-scaling-20 0 0 0 0 0 \u0026lt;none\u0026gt; 3m7s daemonset.apps/gke-metrics-agent-scaling-200 0 0 0 0 0 \u0026lt;none\u0026gt; 3m7s daemonset.apps/gke-metrics-agent-scaling-50 0 0 0 0 0 \u0026lt;none\u0026gt; 3m7s daemonset.apps/gke-metrics-agent-scaling-500 0 0 0 0 0 \u0026lt;none\u0026gt; 3m6s daemonset.apps/gke-metrics-agent-windows 0 0 0 0 0 kubernetes.io/os=windows 3m6s daemonset.apps/kube-proxy 0 0 0 0 0 kubernetes.io/os=linux,node.kubernetes.io/kube-proxy-ds-ready=true 2m38s daemonset.apps/metadata-proxy-v0.1 0 0 0 0 0 cloud.google.com/metadata-proxy-ready=true,kubernetes.io/os=linux 2m35s daemonset.apps/nccl-fastsocket-installer 0 0 0 0 0 \u0026lt;none\u0026gt; 2m49s daemonset.apps/nvidia-gpu-device-plugin-large-cos 0 0 0 0 0 \u0026lt;none\u0026gt; 3m5s daemonset.apps/nvidia-gpu-device-plugin-large-ubuntu 0 0 0 0 0 \u0026lt;none\u0026gt; 3m4s daemonset.apps/nvidia-gpu-device-plugin-medium-cos 0 0 0 0 0 \u0026lt;none\u0026gt; 3m6s daemonset.apps/nvidia-gpu-device-plugin-medium-ubuntu 0 0 0 0 0 \u0026lt;none\u0026gt; 3m5s daemonset.apps/nvidia-gpu-device-plugin-small-cos 0 0 0 0 0 \u0026lt;none\u0026gt; 3m6s daemonset.apps/nvidia-gpu-device-plugin-small-ubuntu 0 0 0 0 0 \u0026lt;none\u0026gt; 3m5s daemonset.apps/pdcsi-node 1 1 1 1 1 kubernetes.io/os=linux 2m46s daemonset.apps/pdcsi-node-windows 0 0 0 0 0 kubernetes.io/os=windows 2m45s daemonset.apps/runsc-metric-server 0 0 0 0 0 kubernetes.io/os=linux,sandbox.gke.io/runtime=gvisor 3m20s daemonset.apps/tpu-device-plugin 0 0 0 0 0 \u0026lt;none\u0026gt; 2m41s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/event-exporter-gke 1/1 1 1 3m15s deployment.apps/konnectivity-agent 1/1 1 1 3m4s deployment.apps/konnectivity-agent-autoscaler 1/1 1 1 3m3s deployment.apps/kube-dns 1/1 1 1 3m24s deployment.apps/kube-dns-autoscaler 1/1 1 1 3m22s deployment.apps/l7-default-backend 1/1 1 1 3m1s deployment.apps/metrics-server-v0.5.2 1/1 1 1 2m50s NAME DESIRED CURRENT READY AGE replicaset.apps/event-exporter-gke-7bf6c99dcb 1 1 1 3m15s replicaset.apps/konnectivity-agent-69fc69d588 1 1 1 3m4s replicaset.apps/konnectivity-agent-autoscaler-5d9dbcc6d8 1 1 1 3m3s replicaset.apps/kube-dns-5bfd847c64 1 1 1 3m23s replicaset.apps/kube-dns-autoscaler-84b8db4dc7 1 1 1 3m22s replicaset.apps/l7-default-backend-d86c96845 1 1 1 3m1s replicaset.apps/metrics-server-v0.5.2-6bf74b5d5f 1 1 1 92s replicaset.apps/metrics-server-v0.5.2-8569bc4cf9 0 0 0 2m50s 沢山ありますね、一つずつメモレベルでまとめていこうかと思います。\n情報間違っていたらすみません。\nDeployment event-exporter-gke ✅ Cluster で発生した Event をキャプチャし Cloud Logging に送信する\nKubetenes Cluster内部で実際に発生したEventはkubectl get eventで取得可能。\n1 2 3 4 ❯ kubectl get event LAST SEEN TYPE REASON OBJECT MESSAGE 55s Normal ScalingReplicaSet deployment/kube-dns Scaled down replica set kube-dns-5bfd847c64 to 1 from 2 しかし、これらのEvent情報は発生から1時間後に削除されてしまう。Cluster内部の異常に気づき、後から調査しようと思ったときにはEventのログが消えていた、となると大変だ。\nそこでevent-exporter-gkeの登場。Event情報をLoggingに送信することで後からでもEvent情報を見ることができ、何よりコンソールから容易に検索が可能となる。\n🚨公式docによるとevent-exporterはベストエフォート方式で動作するため、すべてのEventをキャプチャできるとは限らないらしい。トラブルシューティングの際は、Eventに加えてLogsとMetricsを使用することが推奨されている。\n参考:\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs?hl=ja\nkonnectivity-agent ✅ コントロールプレーンからクラスタへの通信を安全に\nKonnectivity はコントロールプレーンからクラスタへの通信に TCP プロキシを提供するサービスで、コントロールプレーン側に配置された Konnectivity Serverと、クラスタ側に 配置されたKonnectivity Agentの２つの役割から構成されている。\nKonnectivity 登場以前、コントロールプレーンからクラスタ内部への通信には、セキュリティの懸念があるプレーンHTTPや現在非推奨となっているSSHトンネルが利用されていたそう。Konnectivity登場後、Kubernetes API Server がクラスタ内部に直接接続することがなくなったことで、ネットワーキングの分離が可能になり、トラフィックを分割して管理できたりセキュリティの強化ができるようになった。\nkonnectivity-agent-autoscaler は、上記の Konnectivity Agent のスケーリングを制御するものだと認識。\n参考:\nhttps://polar3130.hatenablog.com/entry/2023/05/26/173000\n(参考というかほぼ引用させていただきました)\nhttps://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/#konnectivity-service\nkube-dns ✅ GKE クラスタに内蔵されている DNS サーバ\nkube-dns は、クラスタ内のコンテナが名前解決できるようDNSの設定を行うクラスタ内のDNSサーバで、Serviceとして動いている。\nアーキテクチャ図は以下。kube-dns Service は、kube-dns Pod をグループ化して、単一の IP アドレス（ClusterIP）を割り振る役割を持っており、デフォルトではクラスタ内のすべての Pod がこの Service を使用して DNS クエリを解決する。\nkube-dns-autoscaler は、クラスタの DNS 処理に対応できるように kube-dns をスケーリングする役割を持っている。\n各 Pod の DNS 設定は kubelet が行っており、kube-dns Service の IPアドレスは各コンテナ内のetc/resolv.confに記述されている。\n1 2 3 ❯ k get service kube-dns NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-dns ClusterIP 10.8.0.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 9h nameserver に kube-dns の CLUSTER-IPである10.8.0.10が書いてある。\n1 2 3 4 # cat /etc/resolv.conf search k8sgpt.svc.cluster.local svc.cluster.local cluster.local asia-northeast1-a.c.{hoge}.internal c.{hoge}.internal google.internal nameserver 10.8.0.10 options ndots:5 参考:\nhttps://kubernetes.io/ja/docs/concepts/services-networking/dns-pod-service/\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/kube-dns?hl=ja\nhttps://gadgeterkun.hatenablog.com/entry/20190630/1561864860\nhttps://amateur-engineer-blog.com/kubernetes-dns/\nl7-default-backend ✅ Ingress Controller のこと\nGKE では、Ingress というオブジェクトで、アプリケーションに HTTP(S) トラフィックをルーティングすることができる。 GKE Ingress Controller によって Cloud HTTP(S) ロードバランサが作成され、Ingress および関連する Service の情報に従って構成を行う。この Ingress Controller の Pod が l7-default-backend で、GKEクラスタの HTTP ロードバランシングが「有効」になっていると起動する。\nこの Ingress Controller が NEG(Network Endpoint Groups:GCE_VM_IP_PORT)を作成することで、コンテナに対して直接負荷分散を行うことが可能となり、従来にくらべてコンテナに到達するまでのホップ数を減らし、レイテンシーの向上が期待できる「コンテナネイティブの負荷分散」ができるようになる。\nどんどん話が大きくなりそうなので一旦ここまで。\n参考:\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/ingress?hl=ja\nhttps://cloud.google.com/kubernetes-engine/docs/concepts/container-native-load-balancing?hl=ja\nhttps://qiita.com/ishii1648/items/a9804d96dea275ee28bd\nmetrics-server ✅ クラスタのリソースを取得する\nMetrics Server は Kubelet からクラスタ内のリソース使用状況を収集し、Metrics API を通じて Kubernetes Api Server で公開する。リソース使用状況を収集することで、自動スケーリングやデバッグが容易になる。\nMetrics API には kubectl topでアクセス可能。\nkubectl describeコマンドでは Pod が確保したリソースを確認できるのに対し、こちらのコマンドは実際に Pod 内のコンテナが使用しているリソースの使用量が確認できる。\n1 2 3 4 5 ❯ kubectl top pod -n kube-system NAME CPU(cores) MEMORY(bytes) event-exporter-gke-7bf6c99dcb-ddh8w 1m 20Mi fluentbit-gke-sdpcc 6m 23Mi ... 参考:\nhttps://github.com/kubernetes-sigs/metrics-server\nKubernetes完全ガイド 第2版 (Top Gear)\nDaemonset 全ての Node で動くべき Pod を定義するのが Daemonset 。\n監視やログ収集を行うデーモン等があります。軽く触れていきます。\nfluentbit-gke ✅ 各 Node のコンテナログを Cloud Logging に転送する\nGKE クラスタを作成すると、Cloud Logging および Cloud Monitoring と Cloud Operations for GKE とのインテグレーションがデフォルトで有効になる。\nシステムログとアプリケーション ログは、Cloud Logging のログルーターに配信され、Cloud Logging に取り込まれるか、除外されるか、BigQuery、Pub/Sub、Cloud Storage 等にエクスポートされる。\nシステム ロギングを有効にすると、fluentbit ベースの専用の Logging エージェントである fluentbit-gke が 各ノードに自動的にデプロイされ、ログを Cloud Logging に送信する。\nGKE Standard における Node あたりの Pod 数上限は 110 だったが、2022 年 8 月のアップデートで 256 まで引き上げられた。 fluentbit-gke-256pd はそれに対応するものという認識。\nいずれかの GKE ノードで 1 秒あたり 100 KiB を超えるログ スループットが必要な場合は、高スループット版の fluentbit-gke-max を使用することで、ノードごとに 1 秒あたり 10 MiB という高スループットを実現することができる。\n参考:\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs?hl=ja\nhttps://polar3130.hatenablog.com/entry/2022/08/18/180500\nhttps://polar3130.hatenablog.com/entry/2022/09/21/090000\ngke-metrics-agent ✅ Cloud Monitoring にメトリクスを送信する\nCloud Monitoring にメトリクスを取り込むことで、ダッシュボードでの表示やアラートの生成を行うことができる。gke-metrics-agent は各ノードのメトリクスを Cloud Monitoring に送信する役割を持つ。\ngke-metrics-agent-scaling-10 や gke-metrics-agent-scaling-100 があるが、数字は追加するメモリ量(MB)を表している。\n参考:\nhttps://cloud.google.com/stackdriver/docs/solutions/gke/managing-metrics?hl=ja\nkube-proxy ✅ Service リソースを監視し、ノードのネットワーク設定を行う\nkube-proxy は kubelet と同じく、各Node上で動作するコンポーネント。Service リソースの作成/更新/削除を検知した際に、Node のネットワーク設定を行うことで、 ClusterIP や NodePort 宛のトラフィックが Pod に正常に転送されるようにする。\n3つの転送方式があるが、デフォルトは iptables を構成する iptables モード。\n以下参考ページがわかりやすい。\n参考: https://qiita.com/nozmiz/items/9a74433258a79be26c36\nhttps://recruit.gmo.jp/engineer/jisedai/blog/kubernetes_service/\nmetadata-proxy ✅ コンテナワークロードに隠蔽されたメタデータを提供する\nGKE ではインスタンスメタデータを使用して VM を構成するが、メタデータの一部は機密性が高くクラスタで実行中のワークロードから保護する必要がある。\nmetadata-proxyはこの役割を持つものだが、現在ではメタデータ隠蔽は非推奨となっており、Workload Identity を使うことが推奨されている。\n参考:\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/protecting-cluster-metadata?hl=ja\nhttps://github.com/GoogleCloudPlatform/k8s-metadata-proxy\nnccl-fastsocket-installer ✅ NVIDIAが提供するマルチGPU向けの集合通信のパフォーマンスを向上させる\nNCCLは、NVIDIAが提供するマルチGPU向けの集合通信用のライブラリで、TensorFlow や PyTorch などのディープラーニングフレームワークでマルチ GPU やマルチノードトレーニングを行う場合に使用される。\nnccl-fastsocket-installer は、これらのパフォーマンスを向上させるトランスポート層のプラグインらしい。\n参考:\nhttps://github.com/google/nccl-fastsocket https://cloud.google.com/compute/docs/gpus/optimize-gpus?hl=ja#fast-socket\nnvidia-gpu-device-plugin ✅ NVIDIA製のGPUをクラスタで使えるようにする\nDevice Plugins とは様々なハードウェアを kubelet に見せるための仕組み。\nGKE上では、NVIDIA Tesla® GPU（K80、P100、P4、V100、T4、L4、A100）を装備したノードプールを作成することができ、画像認識や自然言語処理等のディープラーニングに必要な計算能力を提供する。 nvidia-gpu-device-plugin はGKE上で NVIDIA 製の GPU を実行するために必要な plugin 。\n参考:\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/gpus?hl=ja\nhttps://speakerdeck.com/extendwings/device-pluginkai-fa-ru-men\nhttps://kubernetes.io/ja/docs/tasks/manage-gpus/scheduling-gpus/\npdcsi-node ✅ Compute Engine 永続ディスクの CSI ドライバ\nGKE を使用するとクラスタへ簡単かつ自動的に Compute Engine 永続ディスク Container Storage Interface（CSI）ドライバをデプロイして管理することができる。標準クラスタでは、Compute Engine 永続ディスクの CSI ドライバを有効にする必要がある。\n詳しく調べてないが、csi-node-driver-registrarとgcp-compute-persistent-disk-csi-driverという Image が使われていることから、これらに関連するリソースだと思われる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 ❯ kubectl describe daemonsets pdcsi-node --namespace=kube-system ... Pod Template: Labels: k8s-app=gcp-compute-persistent-disk-csi-driver Annotations: components.gke.io/component-name: pdcsi components.gke.io/component-version: 0.16.14 Service Account: pdcsi-node-sa Containers: csi-driver-registrar: Image: gke.gcr.io/csi-node-driver-registrar:v2.8.0-gke.4@sha256:715a1581ce158fbf95f7ca351e25c7d6a0a1599e46e270e72238cc8a0aef1c43 gce-pd-driver: Image: gke.gcr.io/gcp-compute-persistent-disk-csi-driver:v1.10.7-gke.0@sha256:a3e4af6b6f6999427dc7b02e813aa1ca5f26e73357c92a77b8fe774ddf431a26 詳しくは以下の参考ページ。\n参考:\nhttps://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/gce-pd-csi-driver?hl=ja\nhttps://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver\nrunsc-metric-server あまり良くわかってないが、以下の参考サイトと関連ありそう。\n参考:\nhttps://gvisor.dev/docs/user_guide/observability/\ntpu-device-plugin 調べてもあまり情報が出てこなかったが、nvidia-gpu-device-plugin と同様に GKE上で TPU を実行したい場合に必要な plugin だと認識。\nまとめ 今回は Namespace 「kube-system」 にあるリソースがどのような役割を持っているのかメモベースでまとめてみました。なんとなくの理解がハッキリした理解に変わったり、新しく得た知識もありました。\nまだまだ分からないことだらけですが一つずつ潰していきたいです。\nありがとうございました。\n","date":"2023-10-08T15:38:34+09:00","image":"https://blaaackard.com/p/gke-kubesystem-resource/cover_hu55a857987ee61949054669d80844a31c_2738055_120x120_fill_box_smart1_3.png","permalink":"https://blaaackard.com/p/gke-kubesystem-resource/","title":"GKE の kube-system リソースをざっくり理解する"},{"content":"最初に 皆さん、\u0026ldquo;K8sGPT\u0026rdquo; 知っていますか？使ったことありますか？\nGitHub: https://github.com/k8sgpt-ai/k8sgpt/tree/main\nCloud Native Days FUKUOKA 2023に参加した際に、K8sGPTのセッションを聴講して興味を持ったので実際に触ってみました。\nセッション情報: https://event.cloudnativedays.jp/cndf2023/talks/1885\nK8sGPT は Kubernetes クラスタ内の問題を探索し、評価、解説するためのツールです。\nシステム信頼性エンジニアリング(SRE)の専門知識が組み込まれているため、テクニカルな知識に自信がない人でも容易に使うことができます。\n実行自体は本当にシンプルでk8sgpt analyzeというコマンドを叩くだけで実行できます。\n実際にクラスタに問題を発生させて検知してもらいましょう！\nクラスタと問題マニフェストの作成 Kubernetesクラスタの作成が必要な方は作成しましょう。\nまた、K8sGPTに問題を検知させるためのマニフェストを準備します。\n今回はノードの割当可能CPUを超過させるようなものをChatGPTに作ってもらいました🤖\nsample.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 apiVersion: apps/v1 kind: Deployment metadata: name: faulty-deployment namespace: k8sgpt spec: replicas: 3 selector: matchLabels: app: faulty-app template: metadata: labels: app: faulty-app spec: containers: - name: faulty-container image: nginx:latest resources: limits: memory: \u0026#34;128Mi\u0026#34; cpu: \u0026#34;500m\u0026#34; ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: faulty-service namespace: k8sgpt spec: selector: app: faulty-app ports: - protocol: TCP port: 80 targetPort: 8080 CLIのインストール 早速READMEに記載の通りbrewで入れていきます。\n1 2 ❯ brew tap k8sgpt-ai/k8sgpt ❯ brew install k8sgpt APIキーの発行 インストールが完了したらAPIキーを発行する必要があります。\nk8sgpt generateを打つとOpenAIのページに遷移しました。\n🚨OpenAIのアカウント作成が必要です。\n🚨後続の分析ではCreditが必要になります(Min5$から購入できます)。\n1 2 3 4 ❯ k8sgpt generate # Opening: https://beta.openai.com/account/api-keys to generate a key for openai # Please copy the generated key and run `k8sgpt auth` to add it to your config file + Create new secret keyを押すとキーの名前を入力するポップアップが出てくるので、適当な名前を入力してCreate secret keyを押します。\nキーが発行されるのでコピーしておきましょう。\nProviderの設定 1 2 3 ❯ k8sgpt auth add -b openai -m gpt-3.5-turbo -p {COPYしたAPIキー} # openai added to the AI backend provider list ここでいう -bは「backend AI provider」-mは「backend AI model」を意味しています。\nREADME通りのk8sgpt auth addだけだとk8sgpt analyzeコマンドを使って分析自体はできるのですが、explainやFilterを使おうとすると怒られたので明示的に指定しました。\n1 2 3 4 5 6 7 8 ❯ k8sgpt auth add # Warning: backend input is empty, will use the default value: openai # Warning: model input is empty, will use the default value: gpt-3.5-turbo Enter openai Key: # openai added to the AI backend provider list ❯ k8sgpt analyze --explain --namespace=k8sgpt # 0% | (0/12, 0 it/hr) [0s:0s] # Error: failed while calling AI provider openai: error, status code: 400, message: you must provide a model parameter ちなみに今回はOpenAIを指定しましたが、オラクルが支援するCohere等も使えそうでした。\n1 2 3 4 5 6 7 8 9 10 ❯ k8sgpt auth list # Default: # \u0026gt; openai # Active: # \u0026gt; openai # Unused: # \u0026gt; localai # \u0026gt; azureopenai # \u0026gt; noopai # \u0026gt; cohere いざ分析！ 分析自体はk8sgpt analyzeをたたくだけです。\n\u0026ndash;namespace={NAME} や \u0026ndash;filter=Pod など絞り込みもできます。\nServiceはラベルを貼ろうと言われており、DeploymentはCPUリソースが不足していると言われています。\nちゃんとCPUに関する分析結果が出力されて安心しました✌\n1 2 3 4 5 6 7 ❯ k8sgpt analyze --namespace=k8sgpt # AI Provider: openai # 0 k8sgpt/faulty-service(faulty-service) # - Error: Service has no endpoints, expected label app=faulty-app # 1 k8sgpt/faulty-deployment-6879cc8f7f-cntv2(Deployment/faulty-deployment) # - Error: 0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.. \u0026ndash;explain をつけることにより、問題のより詳細な説明を得ることができます。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ❯ k8sgpt analyze --explain --namespace=k8sgpt # 100% |████████████████████████████████| (4/4, 12 it/min) # AI Provider: openai # 0 k8sgpt/faulty-service(faulty-service) # - Error: Service has no endpoints, expected label app=faulty-app # Error: The service has no endpoints and it is expecting the label app=faulty-app. # Solution: # 1. Check the labels of the faulty-app deployment. # 2. Make sure the labels match the selector in the service definition. # 3. Update the labels if necessary. # 4. Restart the deployment and service to apply the changes. # 1 k8sgpt/faulty-deployment-6879cc8f7f-cntv2(Deployment/faulty-deployment) # - Error: 0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.. # Error: 0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.. # Solution: # 1. Check the resource requirements of the pod. # 2. Increase the CPU limits or request values in the pod\u0026#39;s configuration. # 3. Ensure that the cluster has enough available CPU resources. # 4. If necessary, add more nodes to the cluster. # 5. Retry deploying the pod. -l Japanese をつけることで日本語化もできちゃいます。\n「犠牲者が見つかりませんでした。」\u0026hellip;機械的な翻訳になってますが意味は理解できますね🙆‍♂️\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ❯ k8sgpt analyze --explain -l Japanese --namespace=k8sgpt # 100% |████████████████████████████████| (4/4, 9 it/min) # AI Provider: openai # 0 k8sgpt/faulty-service(faulty-service) # - Error: Service has no endpoints, expected label app=faulty-app # Error: サービスにエンドポイントがありません。ラベルapp=faulty-appが期待されています。 # Solution: # 1. kubectl get svcを使用して現在のサービスを確認します。 # 2. kubectl label svc \u0026lt;service-name\u0026gt; app=faulty-appを使用してサービスにラベルを追加します。 # 3. kubectl get endpointsを使用してエンドポイントが正しく追加されたことを確認します。 # 1 k8sgpt/faulty-deployment-6879cc8f7f-cntv2(Deployment/faulty-deployment) # - Error: 0/2 nodes are available: 2 Insufficient cpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod.. # Error: 0/2 ノードが利用可能です: 2 CPU が不足しています。プリエンプション: 0/2 ノードが利用可能です: 2 入力ポッドのプリエンプションの犠牲者が見つかりませんでした。 # Solution: # 1. クラスタ内のノードの CPU リソースを確認します。 # 2. ノードが十分な CPU を持っていることを確認します。 # 3. もしくは、ポッドの CPU リクエストまたは制限を調整します。 # 4. もしくは、他のノードにポッドをスケジュールします。 問題を修正して再デプロイ K8sGPTの分析結果を参考に以下の修正を行います。\nfaulty-serviceにラベルを貼る\n(Solutionでコマンド例を出力してくれてるのでそれ通りに実行します。) 1 2 ❯ kubectl label svc faulty-service app=faulty-app -n k8sgpt # service/faulty-service labeled faulty-deploymentのCPUリソースリミット値をNodeの割当可能な大きさまで下げる 1 2 3 4 5 6 7 8 spec: containers: - name: faulty-container image: nginx:latest resources: limits: memory: \u0026#34;128Mi\u0026#34; cpu: \u0026#34;500m\u0026#34; # \u0026gt;\u0026gt;\u0026#34;50m\u0026#34;に変更 再度分析をすると、、、問題がなくなりました🎉\n1 2 3 4 ❯ k8sgpt analyze --explain -n k8sgpt #AI Provider: openai #No problems detected まとめ 今回はKubernetesクラスタに問題を発生させ、実際にK8sGPTを使用して問題を分析し、修正までをやってみました。\n簡単にクラスタの分析ができることがお分かりいただけたのではないかと思います！\n今回は小規模クラスタ かつ Namespace でフィルターをかけて意図的に分析結果を出してもらいましたが、大規模クラスタの全体検索とかしてみると不適切な設定値のまま放置されているリソースの発見等ができそうですね！\nK8sGPTはまだそこまで一般的になっていませんが、積極的な開発が進んでいます。今後のKubernetes×AIの話題には注目ですね👀\n最後まで読んでくださりありがとうございました。\n","date":"2023-10-07T00:17:43+09:00","image":"https://blaaackard.com/p/k8s-gpt/cover_hu19669f3980519f16624bf304411b5ba5_1909883_120x120_fill_box_smart1_3.png","permalink":"https://blaaackard.com/p/k8s-gpt/","title":"K8sGPTを使ってクラスタのAI分析をしてみよう"}]